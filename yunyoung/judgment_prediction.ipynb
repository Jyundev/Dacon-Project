{"cells":[{"cell_type":"markdown","metadata":{"id":"Xo43zmClneiC"},"source":["### 월간 데이콘 : 법원 판결 예측 AI 경진대회 <font size = 4><a href='https://dacon.io/competitions/official/236112/overview/description'>자세한 정보</a></font>\n","\n","제공 데이터셋에는 미국 대법원 사례의 사건의 식별자와 사건의 내용이 담겨 있습니다.\n","\n","특정 사건에서 첫 번째 당사자와 두 번째 당사자 중 첫 번째 당사자의 승소 여부를 예측하는 AI 모델을 개발해야합니다.\n","\n","\n","#### 데이터 정보\n","\n","    train.csv [파일]\n","    ID : 사건 샘플 ID\n","    first_party : 사건의 첫 번째 당사자\n","    second_party : 사건의 두 번째 당사자\n","    facts : 사건 내용\n","    first_party_winner : 첫 번째 당사자의 승소 여부 (0 : 패배, 1 : 승리)\n","    \n","    test.csv [파일]\n","    ID : 사건 샘플 ID\n","    first_party : 사건의 첫 번째 당사자\n","    second_party : 사건의 두 번째 당사자\n","    facts : 사건 내용\n","    \n","    sample_submission.csv [파일] - 제출 양식\n","    ID : 사건 샘플 ID\n","    first_party_winner : 예측한 첫 번째 당사자의 승소 여부 (0 : 패배, 1 : 승리)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18101,"status":"ok","timestamp":1688303147276,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"uwzN9XknrEwt","outputId":"5c0ce965-3d3c-4b14-bcff-3bc02985a181"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"vNG1H3CNo_YF"},"source":["### 데이터 가져오기"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":608,"status":"ok","timestamp":1688307426722,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"aev-C8XJtrc-"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":69,"status":"ok","timestamp":1688307430507,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"8N5LACsppCrU","outputId":"7e674a02-d892-4a95-e0a2-be720533811e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           ID         first_party                    second_party  \\\n","0  TRAIN_0000   Phil A. St. Amant              Herman A. Thompson   \n","1  TRAIN_0001      Stephen Duncan                  Lawrence Owens   \n","2  TRAIN_0002   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n","3  TRAIN_0003          Linkletter                          Walker   \n","4  TRAIN_0004  William Earl Fikes                         Alabama   \n","\n","                                               facts  first_party_winner  \n","0  On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n","1  Ramon Nelson was riding his bike when he suffe...                   0  \n","2  An Alabama state court convicted Billy Joe Mag...                   1  \n","3  Victor Linkletter was convicted in state court...                   0  \n","4  On April 24, 1953 in Selma, Alabama, an intrud...                   1  "],"text/html":["\n","  <div id=\"df-086f9e1c-9ff3-4f8c-9b22-a7aaea062c18\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>first_party</th>\n","      <th>second_party</th>\n","      <th>facts</th>\n","      <th>first_party_winner</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_0000</td>\n","      <td>Phil A. St. Amant</td>\n","      <td>Herman A. Thompson</td>\n","      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_0001</td>\n","      <td>Stephen Duncan</td>\n","      <td>Lawrence Owens</td>\n","      <td>Ramon Nelson was riding his bike when he suffe...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_0002</td>\n","      <td>Billy Joe Magwood</td>\n","      <td>Tony Patterson, Warden, et al.</td>\n","      <td>An Alabama state court convicted Billy Joe Mag...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_0003</td>\n","      <td>Linkletter</td>\n","      <td>Walker</td>\n","      <td>Victor Linkletter was convicted in state court...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_0004</td>\n","      <td>William Earl Fikes</td>\n","      <td>Alabama</td>\n","      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-086f9e1c-9ff3-4f8c-9b22-a7aaea062c18')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-086f9e1c-9ff3-4f8c-9b22-a7aaea062c18 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-086f9e1c-9ff3-4f8c-9b22-a7aaea062c18');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}],"source":["base_path = '/content/drive/MyDrive/Colab Notebooks/Data Project/Dacon-Project'\n","train = pd.read_csv(base_path + '/all_project/data/train.csv')\n","test = pd.read_csv(base_path + '/all_project/data/test.csv')\n","\n","train.head()"]},{"cell_type":"code","source":["test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"YHkGKxVK5ak9","executionInfo":{"status":"ok","timestamp":1688307435008,"user_tz":-540,"elapsed":444,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"481ec3f1-8fbf-4b95-d262-ab3c6116c719"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          ID                                        first_party  \\\n","0  TEST_0000                                            Salerno   \n","1  TEST_0001             Milberg Weiss Bershad Hynes and Lerach   \n","2  TEST_0002  No. 07-582\\t Title: \\t Federal Communications ...   \n","3  TEST_0003                                    Harold Kaufman    \n","4  TEST_0004                                             Berger   \n","\n","                            second_party  \\\n","0                          United States   \n","1                          Lexecon, Inc.   \n","2  Fox Television Stations, Inc., et al.   \n","3                          United States   \n","4                                 Hanlon   \n","\n","                                               facts  \n","0  The 1984 Bail Reform Act allowed the federal c...  \n","1  Lexecon Inc. was a defendant in a class action...  \n","2  In 2002 and 2003, Fox Television Stations broa...  \n","3  During his trial for armed robbery of a federa...  \n","4  In 1993, a magistrate judge issued a warrant a...  "],"text/html":["\n","  <div id=\"df-b88392a6-1ae4-4a5c-896d-d5f73f516915\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>first_party</th>\n","      <th>second_party</th>\n","      <th>facts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_0000</td>\n","      <td>Salerno</td>\n","      <td>United States</td>\n","      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_0001</td>\n","      <td>Milberg Weiss Bershad Hynes and Lerach</td>\n","      <td>Lexecon, Inc.</td>\n","      <td>Lexecon Inc. was a defendant in a class action...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_0002</td>\n","      <td>No. 07-582\\t Title: \\t Federal Communications ...</td>\n","      <td>Fox Television Stations, Inc., et al.</td>\n","      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_0003</td>\n","      <td>Harold Kaufman</td>\n","      <td>United States</td>\n","      <td>During his trial for armed robbery of a federa...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_0004</td>\n","      <td>Berger</td>\n","      <td>Hanlon</td>\n","      <td>In 1993, a magistrate judge issued a warrant a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b88392a6-1ae4-4a5c-896d-d5f73f516915')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b88392a6-1ae4-4a5c-896d-d5f73f516915 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b88392a6-1ae4-4a5c-896d-d5f73f516915');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"mCLGTHt33Gxr"},"source":["#### 데이터 전처리"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1688307437322,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"CV-3uJ3ipdmc","outputId":"269fa499-6f19-4e66-fa40-084b6389b90d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           ID         first_party                    second_party  \\\n","0  TRAIN_0000   Phil A. St. Amant              Herman A. Thompson   \n","1  TRAIN_0001      Stephen Duncan                  Lawrence Owens   \n","2  TRAIN_0002   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n","3  TRAIN_0003          Linkletter                          Walker   \n","4  TRAIN_0004  William Earl Fikes                         Alabama   \n","\n","                                               facts  first_party_winner  \\\n","0  On June 27, 1962, Phil St. Amant, a candidate ...                   1   \n","1  Ramon Nelson was riding his bike when he suffe...                   0   \n","2  An Alabama state court convicted Billy Joe Mag...                   1   \n","3  Victor Linkletter was convicted in state court...                   0   \n","4  On April 24, 1953 in Selma, Alabama, an intrud...                   1   \n","\n","                                    party_info_facts  \n","0  First party is Phil A. St. Amant and Second pa...  \n","1  First party is Stephen Duncan and Second party...  \n","2  First party is Billy Joe Magwood and Second pa...  \n","3  First party is Linkletter and Second party is ...  \n","4  First party is William Earl Fikes and Second p...  "],"text/html":["\n","  <div id=\"df-3fa0a8ba-50a2-4be2-9097-fee960bf7e79\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>first_party</th>\n","      <th>second_party</th>\n","      <th>facts</th>\n","      <th>first_party_winner</th>\n","      <th>party_info_facts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_0000</td>\n","      <td>Phil A. St. Amant</td>\n","      <td>Herman A. Thompson</td>\n","      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n","      <td>1</td>\n","      <td>First party is Phil A. St. Amant and Second pa...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_0001</td>\n","      <td>Stephen Duncan</td>\n","      <td>Lawrence Owens</td>\n","      <td>Ramon Nelson was riding his bike when he suffe...</td>\n","      <td>0</td>\n","      <td>First party is Stephen Duncan and Second party...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_0002</td>\n","      <td>Billy Joe Magwood</td>\n","      <td>Tony Patterson, Warden, et al.</td>\n","      <td>An Alabama state court convicted Billy Joe Mag...</td>\n","      <td>1</td>\n","      <td>First party is Billy Joe Magwood and Second pa...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_0003</td>\n","      <td>Linkletter</td>\n","      <td>Walker</td>\n","      <td>Victor Linkletter was convicted in state court...</td>\n","      <td>0</td>\n","      <td>First party is Linkletter and Second party is ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_0004</td>\n","      <td>William Earl Fikes</td>\n","      <td>Alabama</td>\n","      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n","      <td>1</td>\n","      <td>First party is William Earl Fikes and Second p...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fa0a8ba-50a2-4be2-9097-fee960bf7e79')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3fa0a8ba-50a2-4be2-9097-fee960bf7e79 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3fa0a8ba-50a2-4be2-9097-fee960bf7e79');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["# first party와 second party 정보가 담긴 party_info_facts 컬럼 추가\n","party_info = 'First party is ' + train.first_party\t+' and Second party is '+train.second_party+'. '+ train.facts\n","train['party_info_facts'] = party_info\n","train.head()"]},{"cell_type":"markdown","metadata":{"id":"Ah1VAV2DneiL"},"source":["### BERT"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4200,"status":"ok","timestamp":1688306418517,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"kKKjBtR9rZzO","outputId":"e055eefd-ed0b-45f3-e27e-9e87df89d2b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9469,"status":"ok","timestamp":1688303733244,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"__XRNjY2vsqU","outputId":"c6af275c-aa4e-4457-c639-1c7b58ae6d22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting adamp\n","  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: adamp\n","  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5980 sha256=bf0f3e34c63d126d612bfac8e4c6083d1ccfd98edba0511f2e587e567b6b1279\n","  Stored in directory: /root/.cache/pip/wheels/c7/ad/0f/b41b1c45b18c66e5eef5d2254415af8055c7e2b0934145157d\n","Successfully built adamp\n","Installing collected packages: adamp\n","Successfully installed adamp-0.3.0\n","Collecting torch_optimizer\n","  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer) (2.0.1+cu118)\n","Collecting pytorch-ranger>=0.1.1 (from torch_optimizer)\n","  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->torch_optimizer) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->torch_optimizer) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torch_optimizer) (1.3.0)\n","Installing collected packages: pytorch-ranger, torch_optimizer\n","Successfully installed pytorch-ranger-0.1.1 torch_optimizer-0.3.0\n"]}],"source":["!pip3 install adamp\n","!pip install torch_optimizer\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4802,"status":"ok","timestamp":1688307449520,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"kxMsSnvLzOkb"},"outputs":[],"source":["from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.utils import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from adamp import AdamP\n","import torch_optimizer as optim\n","\n","\n","import torch\n","import random\n","import time\n","import datetime"]},{"cell_type":"markdown","metadata":{"id":"598pNtFj20ya"},"source":["\n","### GPU 확인"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1688307460662,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"isu72IGnzZyp","outputId":"457facad-f8f7-4156-e2d8-b2dc6f77e8fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","NVIDIA A100-SXM4-40GB\n"]}],"source":["import os\n","\n","n_devices = torch.cuda.device_count()\n","print(n_devices)\n","\n","for i in range(n_devices):\n","    print(torch.cuda.get_device_name(i))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1688307464294,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"cDfeMD4lzv6w","outputId":"f5209c09-64ae-4ecf-9540-3fb9e323548f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2478, 6)\n","(1240, 4)\n"]}],"source":["\n","print(train.shape)\n","print(test.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"NLtNl3w-3ekm"},"source":["### Input Format\n","\n","BERT는 특정 형식의 입력 데이터를 필요로 한다.\n","\n","- special token[sep]은 문장의 끝을 표시하거나 두 문장의 분리할 때 사용한다.\n","- special token[CLS]은 문장 시작할 때 사용한다. 이 토큰은 분류 문제에 사용되지만, 어떤 문제를 풀더라도 입력해야한다.\n","\n","- BERT에서 사용되는 단어사전에 있는 토큰\n","- BERT 토크 나이저의 토큰에 대한 Token ID\n","- 시퀀스에서 어떤 요소가 토큰이고 패딩 요소인지를 나타내는 Mask ID\n","- 다른 문장을 구별하는데 사용되는 Segment ID\n","- 시퀀스 내에서 토큰 위치를 표시하는 데 사용되는 Positional Embeddings\n","\n","<br>\n","\n","####  Special Tokens\n","- [CLS] : 모든 문장의 시작을 알리는 토큰\n","- [SEP] : 두 문장을 구분해주기 위한 토큰\n","\n","<br>\n","\n","BERT는 하나 또는 두개의 문장을 입력으로 사용할 수 있고, 특수 토큰 [SEP]으로 구분한다.\n","\n","[CLS] 토큰은 항상 텍스트 시작 부분에 나타나며 분류 문제를 해결할 때만 사용되지만, 다른 문제를 풀더라도 입력은 무조건 해야한다.\n","<br>\n","\n","\n","**두 문장을 입력하는 경우**\n","\n","> [CLS] The man went to the store. [SEP] He bought a gallon of milk. [SEP]\n","\n","\n","\n","**한 문장을 입력하는 경우**\n","\n","> [CLS] The man went to the store. [SEP]\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":405,"status":"ok","timestamp":1688307472955,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"BdGVRJou3uq5","outputId":"dcedf321-985c-4e8f-d040-9ead076d5387"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] First party is Phil A. St. Amant and Second party is Herman A. Thompson. On June 27, 1962, Phil St. Amant, a candidate for public office, made a television speech in Baton Rouge, Louisiana.  During this speech, St. Amant accused his political opponent of being a Communist and of being involved in criminal activities with the head of the local Teamsters Union.  Finally, St. Amant implicated Herman Thompson, an East Baton Rouge deputy sheriff, in a scheme to move money between the Teamsters Union and St. Amant’s political opponent. \\nThompson successfully sued St. Amant for defamation.  Louisiana’s First Circuit Court of Appeals reversed, holding that Thompson did not show St. Amant acted with “malice.”  Thompson then appealed to the Supreme Court of Louisiana.  That court held that, although public figures forfeit some of their First Amendment protection from defamation, St. Amant accused Thompson of a crime with utter disregard of whether the remarks were true.  Finally, that court held that the First Amendment protects uninhibited, robust debate, rather than an open season to shoot down the good name of anyone who happens to be a public servant. \\n [SEP]',\n"," '[CLS] First party is Stephen Duncan and Second party is Lawrence Owens. Ramon Nelson was riding his bike when he suffered a lethal blow to the back of his head with a baseball bat. After two eyewitnesses identified Lawrence Owens from an array of photos and then a lineup, he was tried and convicted for Nelson’s death. Because Nelson was carrying cocaine and crack cocaine potentially for distribution, the judge at Owens’ bench trial ruled that Owens was probably also a drug dealer and was trying to “knock [Nelson] off.” Owens was found guilty of first-degree murder and sentenced to 25 years in prison.\\nOwens filed a petition for a writ of habeas corpus on the grounds that his constitutional right to due process was violated during the trial. He argued that the eyewitness identification should have been inadmissible based on unreliability and that the judge impermissibly inferred a motive when a motive was not an element of the offense. The district court denied the writ of habeas corpus, and Owens appealed. The U.S. Court of Appeals for the Seventh Circuit reversed the denial and held that the trial judge’s inference about Owens’s motive violated his right to have his guilt adjudicated solely based on the evidence presented at trial.\\n [SEP]']"]},"metadata":{},"execution_count":8}],"source":["bert_sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train.party_info_facts]\n","bert_sentences[:2]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1688307479062,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"7gS9gFHs5WPV","outputId":"c6d9bdab-d364-4f5d-e553-470fdddc83dc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 1, ..., 0, 0, 0])"]},"metadata":{},"execution_count":9}],"source":["# 0'과 '1'의 재판 결과 라벨 컬럼 저장\n","\n","labels = train['first_party_winner'].values\n","labels\n"]},{"cell_type":"markdown","metadata":{"id":"G69_g0L04yNZ"},"source":["#### Tokenization\n","\n","- original word가 subword로 쪼개짐\n","\n","- \"##ant\"는 어떤 단어의 일부, subword라는 뜻. 독립적인 단어 \"ant\"랑 다르다는 것을 보여주기 위해\n","\n","- 전체 단어가 BERT vocab에 없으면 subword로 쪼갠다.\n","\n","- 'OOV' : Out Of Vocabulary\n","\n","- 'UNK' : UNKnown\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7648,"status":"ok","timestamp":1688307494918,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"o-DTvYFI4Gpw","outputId":"0748cf7d-b53b-4628-f9cc-73e21257e048"},"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] First party is Phil A. St. Amant and Second party is Herman A. Thompson. On June 27, 1962, Phil St. Amant, a candidate for public office, made a television speech in Baton Rouge, Louisiana.  During this speech, St. Amant accused his political opponent of being a Communist and of being involved in criminal activities with the head of the local Teamsters Union.  Finally, St. Amant implicated Herman Thompson, an East Baton Rouge deputy sheriff, in a scheme to move money between the Teamsters Union and St. Amant’s political opponent. \n","Thompson successfully sued St. Amant for defamation.  Louisiana’s First Circuit Court of Appeals reversed, holding that Thompson did not show St. Amant acted with “malice.”  Thompson then appealed to the Supreme Court of Louisiana.  That court held that, although public figures forfeit some of their First Amendment protection from defamation, St. Amant accused Thompson of a crime with utter disregard of whether the remarks were true.  Finally, that court held that the First Amendment protects uninhibited, robust debate, rather than an open season to shoot down the good name of anyone who happens to be a public servant. \n"," [SEP]\n","['[CLS]', 'First', 'party', 'is', 'Phil', 'A', '.', 'St', '.', 'Am', '##ant', 'and', 'Second', 'party', 'is', 'Herman', 'A', '.', 'Thompson', '.', 'On', 'June', '27', ',', '1962', ',', 'Phil', 'St', '.', 'Am', '##ant', ',', 'a', 'candidate', 'for', 'public', 'office', ',', 'made', 'a', 'television', 'speech', 'in', 'Baton', 'Rouge', ',', 'Louisiana', '.', 'During', 'this', 'speech', ',', 'St', '.', 'Am', '##ant', 'accused', 'his', 'political', 'opponent', 'of', 'being', 'a', 'Communist', 'and', 'of', 'being', 'involved', 'in', 'criminal', 'activities', 'with', 'the', 'head', 'of', 'the', 'local', 'Teams', '##ters', 'Union', '.', 'Finally', ',', 'St', '.', 'Am', '##ant', 'implicated', 'Herman', 'Thompson', ',', 'an', 'East', 'Baton', 'Rouge', 'deputy', 'sheriff', ',', 'in', 'a', 'scheme', 'to', 'move', 'money', 'between', 'the', 'Teams', '##ters', 'Union', 'and', 'St', '.', 'Am', '##ant', '’', 's', 'political', 'opponent', '.', 'Thompson', 'successfully', 'sued', 'St', '.', 'Am', '##ant', 'for', 'def', '##ama', '##tion', '.', 'Louisiana', '’', 's', 'First', 'Circuit', 'Court', 'of', 'Appeals', 'reversed', ',', 'holding', 'that', 'Thompson', 'did', 'not', 'show', 'St', '.', 'Am', '##ant', 'acted', 'with', '“', 'ma', '##lice', '.', '”', 'Thompson', 'then', 'appealed', 'to', 'the', 'Supreme', 'Court', 'of', 'Louisiana', '.', 'That', 'court', 'held', 'that', ',', 'although', 'public', 'figures', 'for', '##feit', 'some', 'of', 'their', 'First', 'Amendment', 'protection', 'from', 'def', '##ama', '##tion', ',', 'St', '.', 'Am', '##ant', 'accused', 'Thompson', 'of', 'a', 'crime', 'with', 'utter', 'di', '##s', '##regard', 'of', 'whether', 'the', 'remarks', 'were', 'true', '.', 'Finally', ',', 'that', 'court', 'held', 'that', 'the', 'First', 'Amendment', 'protects', 'un', '##in', '##hibit', '##ed', ',', 'robust', 'debate', ',', 'rather', 'than', 'an', 'open', 'season', 'to', 'shoot', 'down', 'the', 'good', 'name', 'of', 'anyone', 'who', 'happens', 'to', 'be', 'a', 'public', 'servant', '.', '[SEP]']\n"]}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(s) for s in bert_sentences]\n","print(bert_sentences[0])\n","print(tokenized_texts[0])"]},{"cell_type":"markdown","metadata":{"id":"uoh_oLaa5HEk"},"source":["#### 패딩\n","token들의 max length보다 크게 MAX_LEN을 설정합니다.\n","\n","설정한 MAX_LEN 만큼 빈 공간을 0이 채웁니다.\n","\n","이 이후에, 문장의 최대 시퀀스를 설정하여 정수 인코딩과 제로 패딩을 수행해준다."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1688307925428,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"IJw79F7Qmulq","outputId":"c17b5f68-0546-4b77-e8b6-aeb797e15c4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["최대 시퀀스 : 1228\n","2478\n","2428\n","2428\n"]}],"source":["#token의 max length 찾기\n","len_list = [ len(token) for idx, token in enumerate(tokenized_texts)]\n","max_idx = np.where(np.array(len_list) == max(len_list))[0][0]\n","print(f'최대 시퀀스 : {max(len_list)}')  #1228로 Bert 최대 시쿼스 512 초과\n","\n","# 512 초과 시퀀스 제거\n","over_length = list(filter(lambda num: num > 512, len_list))\n","indices = [index for index, num in enumerate(len_list) if num in over_length]\n","new_tokenized_texts = [tokenized_texts[i] for i in range(len(tokenized_texts)) if i not in indices]\n","\n","# label 데이터도 동일하게 처리\n","\n","new_labels = [labels[i] for i in range(len(labels)) if i not in indices]\n","\n","\n","\n","print(len(tokenized_texts))\n","print(len(new_tokenized_texts))\n","print(len(new_labels))\n"]},{"cell_type":"markdown","metadata":{"id":"K4dngZRl8nAk"},"source":["#### 최대 시퀀스 512로 조정\n","\n","fact 컬럼에서 상대적으로 중요도가 낮은 초반 문장은 제거"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45520,"status":"ok","timestamp":1688304586813,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"1AcOlU88981n","outputId":"e4b9546b-c967-4d19-c2f6-7ce5d2f90338"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]}],"source":["# !pip install nltk\n","!python -m nltk.downloader all"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"elapsed":1704,"status":"ok","timestamp":1688305698444,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"WBN_yJ5398XW","outputId":"3828d370-0436-48b5-c158-d4a3f18ae46f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["              ID                                   first_party  \\\n","2473  TRAIN_2473  HollyFrontier Cheyenne Refining, LLC, et al.   \n","2474  TRAIN_2474           Grupo Mexicano de Desarrollo, S. A.   \n","2475  TRAIN_2475                                       Peguero   \n","2476  TRAIN_2476        Immigration and Naturalization Service   \n","2477  TRAIN_2477                                       Markman   \n","\n","                             second_party  \\\n","2473  Renewable Fuels Association, et al.   \n","2474             Alliance Bond Fund, Inc.   \n","2475                        United States   \n","2476                              St. Cyr   \n","2477           Westview Instruments, Inc.   \n","\n","                                                  facts  first_party_winner  \\\n","2473  Congress amended the Clean Air Act through the...                   1   \n","2474  Alliance Bond Fund, Inc., an investment fund, ...                   1   \n","2475  In 1992, the District Court sentenced Manuel D...                   0   \n","2476  On March 8, 1996, Enrico St. Cyr, a lawful per...                   0   \n","2477  Herbert Markman owns the patent to a system th...                   0   \n","\n","                                       party_info_facts  \n","2473  First party is Phil A. St. Amant and Second pa...  \n","2474  First party is Phil A. St. Amant and Second pa...  \n","2475  First party is Phil A. St. Amant and Second pa...  \n","2476  First party is Phil A. St. Amant and Second pa...  \n","2477  First party is Phil A. St. Amant and Second pa...  "],"text/html":["\n","  <div id=\"df-4b73ab19-32c4-413e-8255-a20c2379874f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>first_party</th>\n","      <th>second_party</th>\n","      <th>facts</th>\n","      <th>first_party_winner</th>\n","      <th>party_info_facts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2473</th>\n","      <td>TRAIN_2473</td>\n","      <td>HollyFrontier Cheyenne Refining, LLC, et al.</td>\n","      <td>Renewable Fuels Association, et al.</td>\n","      <td>Congress amended the Clean Air Act through the...</td>\n","      <td>1</td>\n","      <td>First party is Phil A. St. Amant and Second pa...</td>\n","    </tr>\n","    <tr>\n","      <th>2474</th>\n","      <td>TRAIN_2474</td>\n","      <td>Grupo Mexicano de Desarrollo, S. A.</td>\n","      <td>Alliance Bond Fund, Inc.</td>\n","      <td>Alliance Bond Fund, Inc., an investment fund, ...</td>\n","      <td>1</td>\n","      <td>First party is Phil A. St. Amant and Second pa...</td>\n","    </tr>\n","    <tr>\n","      <th>2475</th>\n","      <td>TRAIN_2475</td>\n","      <td>Peguero</td>\n","      <td>United States</td>\n","      <td>In 1992, the District Court sentenced Manuel D...</td>\n","      <td>0</td>\n","      <td>First party is Phil A. St. Amant and Second pa...</td>\n","    </tr>\n","    <tr>\n","      <th>2476</th>\n","      <td>TRAIN_2476</td>\n","      <td>Immigration and Naturalization Service</td>\n","      <td>St. Cyr</td>\n","      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n","      <td>0</td>\n","      <td>First party is Phil A. St. Amant and Second pa...</td>\n","    </tr>\n","    <tr>\n","      <th>2477</th>\n","      <td>TRAIN_2477</td>\n","      <td>Markman</td>\n","      <td>Westview Instruments, Inc.</td>\n","      <td>Herbert Markman owns the patent to a system th...</td>\n","      <td>0</td>\n","      <td>First party is Phil A. St. Amant and Second pa...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b73ab19-32c4-413e-8255-a20c2379874f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b73ab19-32c4-413e-8255-a20c2379874f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b73ab19-32c4-413e-8255-a20c2379874f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}],"source":["from nltk import sent_tokenize\n","\n","# train.party_info_facts = train.party_info_facts.apply(lambda x : str(sent_tokenize(x)[0])+''.join(sent_tokenize(x)[2:]))[0]\n","# train.tail()\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121,"status":"ok","timestamp":1688307703706,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"jN1sVJBMHMl5","outputId":"17d0032a-aef7-4834-fb92-d493d4e8e1a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["['[CLS]', 'First', 'party', 'is', 'Phil', 'A', '.', 'St', '.', 'Am', '##ant', 'and', 'Second', 'party', 'is', 'Herman', 'A', '.', 'Thompson', '.', 'On', 'June', '27', ',', '1962', ',', 'Phil', 'St', '.', 'Am', '##ant', ',', 'a', 'candidate', 'for', 'public', 'office', ',', 'made', 'a', 'television', 'speech', 'in', 'Baton', 'Rouge', ',', 'Louisiana', '.', 'During', 'this', 'speech', ',', 'St', '.', 'Am', '##ant', 'accused', 'his', 'political', 'opponent', 'of', 'being', 'a', 'Communist', 'and', 'of', 'being', 'involved', 'in', 'criminal', 'activities', 'with', 'the', 'head', 'of', 'the', 'local', 'Teams', '##ters', 'Union', '.', 'Finally', ',', 'St', '.', 'Am', '##ant', 'implicated', 'Herman', 'Thompson', ',', 'an', 'East', 'Baton', 'Rouge', 'deputy', 'sheriff', ',', 'in', 'a', 'scheme', 'to', 'move', 'money', 'between', 'the', 'Teams', '##ters', 'Union', 'and', 'St', '.', 'Am', '##ant', '’', 's', 'political', 'opponent', '.', 'Thompson', 'successfully', 'sued', 'St', '.', 'Am', '##ant', 'for', 'def', '##ama', '##tion', '.', 'Louisiana', '’', 's', 'First', 'Circuit', 'Court', 'of', 'Appeals', 'reversed', ',', 'holding', 'that', 'Thompson', 'did', 'not', 'show', 'St', '.', 'Am', '##ant', 'acted', 'with', '“', 'ma', '##lice', '.', '”', 'Thompson', 'then', 'appealed', 'to', 'the', 'Supreme', 'Court', 'of', 'Louisiana', '.', 'That', 'court', 'held', 'that', ',', 'although', 'public', 'figures', 'for', '##feit', 'some', 'of', 'their', 'First', 'Amendment', 'protection', 'from', 'def', '##ama', '##tion', ',', 'St', '.', 'Am', '##ant', 'accused', 'Thompson', 'of', 'a', 'crime', 'with', 'utter', 'di', '##s', '##regard', 'of', 'whether', 'the', 'remarks', 'were', 'true', '.', 'Finally', ',', 'that', 'court', 'held', 'that', 'the', 'First', 'Amendment', 'protects', 'un', '##in', '##hibit', '##ed', ',', 'robust', 'debate', ',', 'rather', 'than', 'an', 'open', 'season', 'to', 'shoot', 'down', 'the', 'good', 'name', 'of', 'anyone', 'who', 'happens', 'to', 'be', 'a', 'public', 'servant', '.', '[SEP]']\n","최대 시퀀스 : 512\n"]}],"source":["# bert_sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train.party_info_facts]\n","# tokenized_texts = [tokenizer.tokenize(s) for s in bert_sentences]\n","\n","#token의 max length 찾기\n","len_list = [ len(token) for idx, token in enumerate(new_tokenized_texts)]\n","max_idx = np.where(np.array(len_list) == max(len_list))[0][0]\n","print(new_tokenized_texts[0])\n","print(f'최대 시퀀스 : {max(len_list)}')  #512"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":859,"status":"ok","timestamp":1688307762269,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"PCiPq4sF48Tz","outputId":"2e536312-1da6-4848-b5eb-fe8f9e351ada"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  101,  1752,  1710,  1110,  8067, 22686,   117,  3084,   119,\n","        2393,   119,  1105,  2307,  1710,  1110,  4769,  2250,  1104,\n","        3398,   119,  1130,  1347,  1816,   117,  1210, 24574,  5680,\n","       12555,  8390,  2310,  1146,  1107,  1126,   170, 11090,  1298,\n","        1107,  6167,   119,  3841,  1103,  4475,  1127,  2022,   158,\n","         119,   156,   119,  4037,   117,  1150, 14007,  5770,   170,\n","        9680,  1222,  1103,  4769,  2250,  1104,  3398,  1111,  1157,\n","        1648,  1107,  3558,  2578,  1619,  1106,  1103, 19450,   119,\n","        1130,  1704,   117, 14611,  6670,  1132, 11650,  1121,  9680,\n","         117,  1133,  1103,  4201, 24600,   146,  6262, 19782,  4338,\n","        2173,   113,   107,   143, 13882,  1592,   107,   114,  2790,\n","        1126,  5856,  1106,  1115, 17523,  1107,  2740,  1104,  1352,\n","         118,  5988,  1104, 12010,   119,   138,  1629,  3942,  1107,\n","         141,   119,   140,   119,  2242,   170,   109,  5729,   119,\n","         126,  1550, 12973,  9228,  1222,  3398,   117,  1134,  3398,\n","        1225,  1136,  2653,   119,  1109, 23940,  1116,  1173,  4941,\n","       25342,  1181,  2567,  2740,  1506,  1103,  1583,  1107,  1126,\n","        2661,  1106, 25337,  1105, 16621,  1113,  7239,  6661,  1106,\n","       13692,  1103,  9228,   119,  1109,  1692,  1120,  1289,  6808,\n","        1300,  6286,  1104,  2890,  3886, 10701,  1439,  1103,  6224,\n","        1104,  1103,  1239,  1104,  2290,  1105,  2290,   112,   188,\n","        3479,  2143,  1104,  6240,  2892,   119,  1556,  1374, 12408,\n","         117,   170,  2880,  1352,   112,   188,  2400,  1107,  1103,\n","        1244,  1311,  1110, 11650,  1121, 15708,  1105,  7581,   119,\n","        1109, 23940,  1116,  4491,  1196,  1103,  1629,  2175,  1115,\n","        1152,  1431,  1129,  1682,  1106, 25337,  1105, 16621,  3398,\n","         112,   188,  2400,  1223,  4841, 25461,  1116,   113,   170,\n","         114,  1105,   113,   176,   114,  1104,  1743,   158,   119,\n","         156,   119,   140,   119,   204, 18563,  1568,   117,  1112,\n","        1218,  1112,  2237, 17365,  1104,  1103, 27792, 19547, 11037,\n","        2173,  1104,  1617,   113,   107,   157, 20595,  1592,   107,\n","         114,   119,  1109,  1629,  2175,  1316,   117,  1105,  1103,\n","       13121,  7887,  2675,   117,  1115,  1229,   204, 18563,  1568,\n","         113,   170,   114, 15267,  7581,  1113,   170,  2880,  1352,\n","         112,   188,  2400,   107,  1215,  1111,   170,  2595,  3246,\n","        1107,  1103,  1244,  1311,   117,   107,  1115,  9348,  5315,\n","        1329,  1118,  1103,  2880,  1352,  2111,   117,  1136,   170,\n","        1503,  1710,   113,  1216,  1112,   170,  3480,   114,   119,\n","        1109,  1629,  2175,  1145,  1316,   117,  1105,  1103, 13121,\n","        7887,  2675,   117,  1115,   204, 18563,  1568,   113,   176,\n","         114, 15267, 15708,  1106,  2400,  1104,   170,  2880,  1352,\n","        1107,  4256,  1104,  7581,  1178,  1107,  2740,  1758,  6890,\n","        1107,   204, 18563,  1568,   117, 15171,  1115,  9348, 22254,\n","        1106,  1103, 23940,  1116,  1107,  1142,  1692,   119,  4428,\n","         117,  1103,  1629,  2175,  1316,   117,  1105,  1103, 13121,\n","        7887,  2675,   117,  1115,   204, 17365,  1104,   157, 20595,\n","        1592, 12175,  1178,  1106,  6661,  8192,  1118,  3275,  1546,\n","         117,  1105,  1107,  1103,  5884,  1104,  1126,  3275,  1546,\n","       11016,  1103,  2440,  6661,  4110,   117, 23940,  1116,  2834,\n","       28057,  2310,  1104,  1115,  9348,  1719,   119,  1109, 13121,\n","        7887,   112,   188,  2355,  2456,  9802,  1114,  1103, 19066,\n","        7887,   112,   188,  2988,  2355,  1115,   204, 18563,  1568,\n","         113,   176,   114,  2790,   170,  1714, 17277, 15708, 17523,\n","        5856,  1115,  3643, 12010,  5256,  1106, 25337,  1105, 16621,\n","        1852,  1251,  6661,  1104,  2880,  1352, 13942,  1104, 12010,\n","         117,  8334,  1104,  2480,  1103,  6661,  1132,  4303,  2548,\n","        1106,  7581,  1223,  2237, 18563,  1568,   119,   102])"]},"metadata":{},"execution_count":15}],"source":["MAX_LEN = 512 #최대 시퀀스 길이 설정\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in new_tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","input_ids[max_idx]"]},{"cell_type":"markdown","metadata":{"id":"wNiOnKIV6dXc"},"source":["#### 어텐션 마스크\n","텐션 마스크란 0 값을 가지는 패딩 토큰에 대해서 어텐션 연산을 불필요하게 수행하지 않도록 단어와 패딩 토큰을 구분할 수 있게 알려주는 것을 말한다.\n","\n"," 패딩된 값은 '0', 패딩되지 않은 단어는 '1'의 값을 갖는다.\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":761,"status":"ok","timestamp":1688307772026,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"b53h1dCg65BK","outputId":"9d2a1f34-fa2f-4185-b39d-fa821c430075"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0]"]},"metadata":{},"execution_count":16}],"source":["attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","attention_masks[0]\n"]},{"cell_type":"markdown","metadata":{"id":"wFbzPFga7695"},"source":["### 훈련셋과 검증셋으로 분리하기\n","\n","어텐션 마스크도 함께 훈련셋과 검증셋으로 분리하고, 데이터를 모두 파이토치 텐서로 변환시킨다\n"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":533,"status":"ok","timestamp":1688307946674,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"BVbOPkVT8Hr0"},"outputs":[],"source":["train_X, val_X, train_y, val_y = train_test_split(input_ids,new_labels,random_state=42,test_size=0.1)\n","\n","train_masks, val_masks, _, _ = train_test_split(attention_masks,\n","                                                       input_ids,\n","                                                       random_state=42,\n","                                                       test_size=0.1)\n","\n","# 파이토치 텐서로 변환\n","train_inputs = torch.tensor(train_X)\n","train_labels = torch.tensor(train_y)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(val_X)\n","validation_labels = torch.tensor(val_y)\n","validation_masks = torch.tensor(val_masks)"]},{"cell_type":"markdown","metadata":{"id":"dy7GzSl48PuU"},"source":["#### 데이터로더 설정\n","입력데이터, 어텐션 마스크, 라벨을 하나의 데이터로 묶어 train_dataloader, validation_dataloader라는 입력데이터를 생성"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":332,"status":"ok","timestamp":1688307956726,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"HnjOIwoS8e4N"},"outputs":[],"source":["def get_train_validation_dataloader(batch_size, train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels ):\n","  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","  train_sampler = RandomSampler(train_data)\n","  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","  validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","  validation_sampler = SequentialSampler(validation_data)\n","  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","  return train_dataloader, validation_dataloader\n","\n","\n","batch_size = 16\n","train_dataloader, validation_dataloader =  get_train_validation_dataloader(batch_size, train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels )\n"]},{"cell_type":"markdown","metadata":{"id":"NPEfQsgW8gNX"},"source":["### 테스트셋 전처리\n","Train 데이터와 동일하게 전처리해준다"]},{"cell_type":"code","source":["test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"1OfWhSZj4-iZ","executionInfo":{"status":"ok","timestamp":1688307959341,"user_tz":-540,"elapsed":337,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"b28f402c-a9ae-4852-fc9a-cb4d17d029b7"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          ID                                        first_party  \\\n","0  TEST_0000                                            Salerno   \n","1  TEST_0001             Milberg Weiss Bershad Hynes and Lerach   \n","2  TEST_0002  No. 07-582\\t Title: \\t Federal Communications ...   \n","3  TEST_0003                                    Harold Kaufman    \n","4  TEST_0004                                             Berger   \n","\n","                            second_party  \\\n","0                          United States   \n","1                          Lexecon, Inc.   \n","2  Fox Television Stations, Inc., et al.   \n","3                          United States   \n","4                                 Hanlon   \n","\n","                                               facts  \n","0  The 1984 Bail Reform Act allowed the federal c...  \n","1  Lexecon Inc. was a defendant in a class action...  \n","2  In 2002 and 2003, Fox Television Stations broa...  \n","3  During his trial for armed robbery of a federa...  \n","4  In 1993, a magistrate judge issued a warrant a...  "],"text/html":["\n","  <div id=\"df-720bacc7-82e4-4d37-97a2-2dbc84c238da\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>first_party</th>\n","      <th>second_party</th>\n","      <th>facts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_0000</td>\n","      <td>Salerno</td>\n","      <td>United States</td>\n","      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_0001</td>\n","      <td>Milberg Weiss Bershad Hynes and Lerach</td>\n","      <td>Lexecon, Inc.</td>\n","      <td>Lexecon Inc. was a defendant in a class action...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_0002</td>\n","      <td>No. 07-582\\t Title: \\t Federal Communications ...</td>\n","      <td>Fox Television Stations, Inc., et al.</td>\n","      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_0003</td>\n","      <td>Harold Kaufman</td>\n","      <td>United States</td>\n","      <td>During his trial for armed robbery of a federa...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_0004</td>\n","      <td>Berger</td>\n","      <td>Hanlon</td>\n","      <td>In 1993, a magistrate judge issued a warrant a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-720bacc7-82e4-4d37-97a2-2dbc84c238da')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-720bacc7-82e4-4d37-97a2-2dbc84c238da button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-720bacc7-82e4-4d37-97a2-2dbc84c238da');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3287,"status":"ok","timestamp":1688308106694,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"JgdhNjwxlGz4","outputId":"0469d8df-1117-4d31-eb71-3b97cfaebf6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["최대 시퀀스 : 1283\n","tokenized_texts_test size :  1240\n","new_tokenized_texts_test size :  1210\n"]}],"source":["# first party와 second party 정보가 담긴 party_info_facts 컬럼 추가\n","party_info = 'First party is ' + test.first_party\t+' and Second party is '+test.second_party+'. '+ test.facts\n","test['party_info_facts'] = party_info\n","\n","\n","# [CLS] + 문장 + [SEP]\n","bert_sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in test.party_info_facts]\n","\n","\n","# Word 토크나이저 토큰화\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n","tokenized_texts_test = [tokenizer.tokenize(sent) for sent in bert_sentences]\n","\n","#token의 max length 찾기\n","len_list = [ len(token) for idx, token in enumerate(tokenized_texts_test)]\n","max_idx = np.where(np.array(len_list) == max(len_list))[0][0]\n","print(f'최대 시퀀스 : {max(len_list)}')\n","\n","# 512 초과 시퀀스 제거\n","over_length = list(filter(lambda num: num > 512, len_list))\n","indices = [index for index, num in enumerate(len_list) if num in over_length]\n","new_tokenized_texts_test = [tokenized_texts_test[i] for i in range(len(tokenized_texts_test)) if i not in indices]\n","\n","print('tokenized_texts_test size : ',len(tokenized_texts_test))\n","print('new_tokenized_texts_test size : ',len(new_tokenized_texts_test))\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":1037,"status":"ok","timestamp":1688308256699,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"4h0gWfAS8kJZ"},"outputs":[],"source":["# 시퀀스 설정 및 패딩\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in new_tokenized_texts_test]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# 어텐션 마스크\n","attention_masks = []\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","# 파이토치 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_masks = torch.tensor(attention_masks)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KlBwmjmZEkxx"},"source":["### 모델 학습"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcI9uo7HFmEY","executionInfo":{"status":"ok","timestamp":1688308612691,"user_tz":-540,"elapsed":23,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"c4c65865-d983-4c32-8dfa-439b45733ecb"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: NVIDIA A100-SXM4-40GB\n"]}],"source":["# GPU 설정\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')\n"]},{"cell_type":"markdown","metadata":{"id":"rGBYuitkmYJL"},"source":["#### BERT 모델 생성"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1556,"status":"ok","timestamp":1688308619739,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"LUNUP2wcGTXT","outputId":"faf1d562-7f34-41bc-e084-baacebc3adff"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":29}],"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2) # 이진분류\n","model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"YT4cImG5mpEZ"},"source":["\n","#### 옵티마이, 스케줄러 설정\n","\n","- AdamW\n","- AdamP\n","- RAdam\n"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":545,"status":"ok","timestamp":1688308626956,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"Nw4MirQCGair","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba25123c-c380-4193-f8df-c65572e1ecd1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# 옵티마이저\n","optimizer_AdamW = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률(learning rate)\n","                  eps = 1e-8\n","                )\n","optimizer_AdamP = AdamP(model.parameters(),\n","                  lr = 2e-5, # 학습률(learning rate)\n","                  betas=(0.9, 0.999),\n","                  weight_decay=1e-2,\n","                  eps = 1e-8\n","                )\n","\n","optimizer_RAdam = optim.RAdam(model.parameters(),\n","                  lr = 2e-5, # 학습률(learning rate)\n","                  betas=(0.9, 0.999),\n","                  weight_decay=0,\n","                  eps = 1e-8,\n","                )\n","\n","\n","# 에폭수\n","epochs = 5\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","# 스케줄러 생성 : Learning rate decay\n","scheduler_AdamW = get_linear_schedule_with_warmup(optimizer_AdamW,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","scheduler_AdamP = get_linear_schedule_with_warmup(optimizer_AdamP,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","scheduler_RAdam = get_linear_schedule_with_warmup(optimizer_RAdam,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n"]},{"cell_type":"markdown","metadata":{"id":"nG-cm3xFGflw"},"source":["### 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"R3rsVum74XZ_"},"source":["#### 함수 생성"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1688308636626,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"bjd9apH3GiqK"},"outputs":[],"source":["# 정확도 계산 함수\n","def accuracy_measure(preds, labels):\n","\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","# 시간 표시 함수\n","def time_elapsed(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1688308964934,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"s22G39CHGj5l"},"outputs":[],"source":["def model_train(model_case, optimizer, scheduler, train_dataloader, validation_dataloader):\n","  #랜덤시드 고정\n","  seed_val = 42\n","  random.seed(seed_val)\n","  np.random.seed(seed_val)\n","  torch.manual_seed(seed_val)\n","  torch.cuda.manual_seed_all(seed_val)\n","\n","  #그래디언트 초기화\n","  model.zero_grad()\n","\n","  # 학습\n","  for epoch_i in range(0, epochs):\n","\n","      print(\"\")\n","      print('======== Train Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","      print('Training...')\n","\n","      # 시작 시간 설정\n","      t0 = time.time()\n","\n","      total_loss = 0\n","\n","      # 훈련모드로 변경\n","      model.train()\n","\n","      # 데이터로더에서 배치만큼 반복하여 가져옴\n","      for step, batch in enumerate(train_dataloader):\n","          # 경과 정보 표시\n","          if step % 500 == 0 and not step == 0:\n","              elapsed = time_elapsed(time.time() - t0)\n","              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","          # 배치를 GPU에 넣음\n","          batch = tuple(t.to(device) for t in batch)\n","\n","          # 배치에서 데이터 추출\n","          b_input_ids, b_input_mask, b_labels = batch\n","\n","          # Forward 수행\n","          outputs = model(b_input_ids,\n","                          token_type_ids=None,\n","                          attention_mask=b_input_mask,\n","                          labels=b_labels)\n","\n","          # 로스 구함\n","          loss = outputs[0]\n","\n","          # 총 로스 계산\n","          total_loss += loss.item()\n","\n","          # Backward 수행으로 그래디언트 계산\n","          loss.backward()\n","\n","          # 그래디언트 클리핑\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","          # 그래디언트를 통해 가중치 파라미터 업데이트\n","          optimizer.step()\n","\n","          # 스케줄러로 학습률 감소\n","          scheduler.step()\n","\n","          # 그래디언트 초기화\n","          model.zero_grad()\n","\n","      # 평균 로스 계산\n","      avg_train_loss = total_loss / len(train_dataloader)\n","\n","      print(\"\")\n","      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","      print(\"  Training epcoh took: {:}\".format(time_elapsed(time.time() - t0)))\n","\n","\n","\n","      print()\n","      print(\"Validation...\")\n","\n","      #시작 시간 설정\n","      t0 = time.time()\n","\n","      # 평가모드로 변경\n","      model.eval()\n","\n","      # 변수 초기화\n","      eval_loss, eval_accuracy = 0, 0\n","      nb_eval_steps, nb_eval_examples = 0, 0\n","\n","      # 데이터로더에서 배치만큼 반복하여 가져옴\n","      for batch in validation_dataloader:\n","          # 배치를 GPU에 넣음\n","          batch = tuple(t.to(device) for t in batch)\n","\n","          # 배치에서 데이터 추출\n","          b_input_ids, b_input_mask, b_labels = batch\n","          # 그래디언트 계산 안함\n","          with torch.no_grad():\n","              # Forward 수행\n","              outputs = model(b_input_ids,\n","                              token_type_ids=None,\n","                              attention_mask=b_input_mask)\n","\n","          # 로스 구함\n","          logits = outputs[0]\n","\n","          # CPU로 데이터 이동\n","          logits = logits.detach().cpu().numpy()\n","          label_ids = b_labels.to('cpu').numpy()\n","\n","          # 출력 로짓과 라벨을 비교하여 정확도 계산\n","          tmp_eval_accuracy = accuracy_measure(logits, label_ids)\n","          eval_accuracy += tmp_eval_accuracy\n","          nb_eval_steps += 1\n","\n","      print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","      print(\"  Validation took: {:}\".format(time_elapsed(time.time() - t0)))\n","\n","\n","\n","  print()\n","  print(\"======== COMPLETE ========\")\n","  add_result(model_case, round(eval_accuracy/nb_eval_steps,3), batch_size, epochs )"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":359,"status":"ok","timestamp":1688308971103,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"YTz-K3DJBZFH"},"outputs":[],"source":["result_df = pd.DataFrame({'case' : [],\n","              'accuracy ' : [],\n","              'batch_size' : [],\n","              'epochs' : []\n","              })"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1688308975260,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"O-LhrQAexiYj"},"outputs":[],"source":["def add_result(model_type, accuracy, batch_size, epochs):\n","  result_df.loc[len(result_df)] = [model_type, accuracy, batch_size, epochs]"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1688304812180,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"DyrBSXOtLDmU"},"outputs":[],"source":["def get_eval_accuracy(model_case, test_dataloader, batch_size):\n","  #시작 시간 설정\n","  t0 = time.time()\n","\n","  # 평가모드로 변경\n","  model.eval()\n","\n","  # 변수 초기화\n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","\n","  # 데이터로더에서 배치만큼 반복하여 가져옴\n","  for step, batch in enumerate(test_dataloader):\n","      # 경과 정보 표시\n","      if step % 100 == 0 and not step == 0:\n","          elapsed = time_elapsed(time.time() - t0)\n","          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","      # 배치를 GPU에 넣음\n","      batch = tuple(t.to(device) for t in batch)\n","\n","      # 배치에서 데이터 추출\n","      b_input_ids, b_input_mask, b_labels = batch\n","\n","      # 그래디언트 계산 안함\n","      with torch.no_grad():\n","          # Forward 수행\n","          outputs = model(b_input_ids,\n","                          token_type_ids=None,\n","                          attention_mask=b_input_mask)\n","\n","      # 로스 구함\n","      logits = outputs[0]\n","\n","      # CPU로 데이터 이동\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","\n","      # 출력 로짓과 라벨을 비교하여 정확도 계산\n","      tmp_eval_accuracy = accuracy_measure(logits, label_ids)\n","      eval_accuracy += tmp_eval_accuracy\n","      nb_eval_steps += 1\n","\n","  add_result(model_case, round(eval_accuracy/nb_eval_steps,2),batch_size)\n","  print(\"\")\n","  print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","  print(\"Test took: {:}\".format(time_elapsed(time.time() - t0)))"]},{"cell_type":"markdown","metadata":{"id":"CoxfAGtO0nLS"},"source":["#### 모델 학습\n","스케줄러 생성\n","- optimizer_AdamW, scheduler_AdamW\n","- optimizer_AdamP, scheduler_AdamP\n","- optimizer_RAdam, scheduler_RAdam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDh6F0G24hO3","outputId":"eb7c32f8-33bb-4b76-b154-c939781b8e2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:00:50\n","\n","Validation...\n","  Accuracy: 0.64\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:00:50\n","\n","Validation...\n","  Accuracy: 0.64\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","\n","  Average training loss: 0.58\n","  Training epcoh took: 0:00:50\n","\n","Validation...\n","  Accuracy: 0.60\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","\n","  Average training loss: 0.41\n","  Training epcoh took: 0:00:50\n","\n","Validation...\n","  Accuracy: 0.63\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:00:50\n","\n","Validation...\n","  Accuracy: 0.62\n","  Validation took: 0:00:02\n","\n","======== COMPLETE ========\n","\n","======== Train Epoch 1 / 5 ========\n","Training...\n","\n","  Average training loss: 0.25\n","  Training epcoh took: 0:00:56\n","\n","Validation...\n","  Accuracy: 0.57\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","\n","  Average training loss: 0.11\n","  Training epcoh took: 0:00:56\n","\n","Validation...\n","  Accuracy: 0.60\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n"]}],"source":["model_train('optimizer_AdamW', optimizer_AdamW, scheduler_AdamW,  train_dataloader, validation_dataloader)\n","# get_eval_accuracy('optimizer_AdamW, test_dataloader, batch_size)\n","model_train('optimizer_AdamP', optimizer_AdamP, scheduler_AdamP,  train_dataloader, validation_dataloader)\n","# get_eval_accuracy('optimizer_AdamP', test_dataloader, batch_size)\n","model_train('optimizer_RAdam', optimizer_RAdam, scheduler_RAdam,  train_dataloader, validation_dataloader)\n","# get_eval_accuracy('optimizer_RAdam', test_dataloader, batch_size)"]},{"cell_type":"markdown","metadata":{"id":"1DmtZg2IDYAc"},"source":["### 성능 평가\n","\n","accuracy 는 다 동일하지만 평균 loss 는  optimizer_RAdam 0.63 으로 가장 작었다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1688292132700,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"IqkslEb558zf","outputId":"2271ed50-a849-446e-f9e7-4452157d1c6d"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-97216a34-15f5-4b22-a4c1-7e69d09f071f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>case</th>\n","      <th>accuracy</th>\n","      <th>batch_size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>optimizer_AdamW</td>\n","      <td>0.67</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>optimizer_AdamP</td>\n","      <td>0.67</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>optimizer_RAdam</td>\n","      <td>0.67</td>\n","      <td>16</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97216a34-15f5-4b22-a4c1-7e69d09f071f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-97216a34-15f5-4b22-a4c1-7e69d09f071f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-97216a34-15f5-4b22-a4c1-7e69d09f071f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["              case  accuracy  batch_size\n","0  optimizer_AdamW      0.67          16\n","1  optimizer_AdamP      0.67          16\n","2  optimizer_RAdam      0.67          16"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["result_df"]},{"cell_type":"markdown","metadata":{"id":"fEPVdzGYEdyf"},"source":["### Hyperparemeter Tunning\n","\n","#### 1. batch_size 조정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kr-2daAR_xRg"},"outputs":[],"source":["batch_size = 20 # 16 -> 20\n","\n","train_dataloader, validation_dataloader =  get_train_validation_dataloader(batch_size, train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels )\n","test_dataloader = get_test_dataloader(batch_size, test_inputs, test_masks, test_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOho0fEXDAQG"},"outputs":[],"source":["optimizer_RAdam = optim.RAdam(model.parameters(),\n","                  lr = 2e-5, # 학습률(learning rate)\n","                  betas=(0.9, 0.999),\n","                  weight_decay=0,\n","                  eps = 1e-8,\n","                )\n","# 에폭수\n","epochs = 5\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler_RAdam = get_linear_schedule_with_warmup(optimizer_RAdam,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":501951,"status":"ok","timestamp":1688293518911,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"0HrbbeJDEP6e","outputId":"7a4f5863-6c39-4ee5-d031-82ef41e81fc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:25\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:01:24\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:01:24\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:08\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:24\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:08\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:24\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== COMPLETE ========\n","  Batch   100  of    124.    Elapsed: 0:00:30.\n","\n","Accuracy: 0.67\n","Test took: 0:00:38\n"]}],"source":["model_train(optimizer_RAdam, scheduler_RAdam,  train_dataloader, validation_dataloader)\n","get_eval_accuracy('optimizer_RAdam', test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hs8V1dwcIcmo"},"outputs":[],"source":["batch_size = 10 # 16->20->10\n","\n","train_dataloader, validation_dataloader =  get_train_validation_dataloader(batch_size, train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels )\n","test_dataloader = get_test_dataloader(batch_size, test_inputs, test_masks, test_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506524,"status":"ok","timestamp":1688295225846,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"OU240NnFEa3C","outputId":"a2801a00-fe8a-4c66-eb4f-50a8c5a2dcb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== COMPLETE ========\n","  Batch   100  of    248.    Elapsed: 0:00:15.\n","  Batch   200  of    248.    Elapsed: 0:00:30.\n","\n","Accuracy: 0.67\n","Test took: 0:00:37\n"]}],"source":["optimizer_RAdam = optim.RAdam(model.parameters(),\n","                  lr = 2e-5, # 학습률(learning rate)\n","                  betas=(0.9, 0.999),\n","                  weight_decay=0,\n","                  eps = 1e-8,\n","                )\n","# 에폭수\n","epochs = 5\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler_RAdam = get_linear_schedule_with_warmup(optimizer_RAdam,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","\n","model_train(optimizer_RAdam, scheduler_RAdam,  train_dataloader, validation_dataloader)\n","get_eval_accuracy('optimizer_RAdam', test_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"4l0xKyQEPSWP"},"source":["#### 2. Learning Rate 조정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":508278,"status":"ok","timestamp":1688295758512,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"gfuWXZ4gI2Mv","outputId":"a8e97a23-2027-4c1b-b91f-644e017dca44"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:28\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","\n","  Average training loss: 0.62\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== COMPLETE ========\n","  Batch   100  of    248.    Elapsed: 0:00:15.\n","  Batch   200  of    248.    Elapsed: 0:00:30.\n","\n","Accuracy: 0.67\n","Test took: 0:00:37\n"]}],"source":["optimizer_RAdam = optim.RAdam(model.parameters(),\n","                  lr = 1e-5, # 학습률(learning rate)\n","                  betas=(0.9, 0.999),\n","                  weight_decay=0,\n","                  eps = 1e-8,\n","                )\n","# 에폭수\n","epochs = 5\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler_RAdam = get_linear_schedule_with_warmup(optimizer_RAdam,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","\n","model_train(optimizer_RAdam, scheduler_RAdam,  train_dataloader, validation_dataloader)\n","get_eval_accuracy('optimizer_RAdam', test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kQDgNdUSYJP"},"outputs":[],"source":["#### 3. epochs 증가"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1895235,"status":"error","timestamp":1688298936304,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"dtFhkFJJPNJo","outputId":"bbc7e4d7-487d-471e-9c29-e436b322b290"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Train Epoch 1 / 50 ========\n","Training...\n","\n","  Average training loss: 0.61\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 2 / 50 ========\n","Training...\n","\n","  Average training loss: 0.43\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.34\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 3 / 50 ========\n","Training...\n","\n","  Average training loss: 0.42\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 4 / 50 ========\n","Training...\n","\n","  Average training loss: 0.53\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.34\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 5 / 50 ========\n","Training...\n","\n","  Average training loss: 0.61\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 6 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 7 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 8 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 9 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 10 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:27\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 11 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 12 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 13 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 14 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 15 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 16 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 17 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 18 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 19 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 20 / 50 ========\n","Training...\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:01:26\n","\n","Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:07\n","\n","======== Train Epoch 21 / 50 ========\n","Training...\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-118-79475cff0b52>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_RAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_RAdam\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mget_eval_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optimizer_RAdam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-82-08ada394a309>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(optimizer, scheduler, train_dataloader, validation_dataloader)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0;31m# 그래디언트 클리핑\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m           \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;31m# 그래디언트를 통해 가중치 파라미터 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["optimizer_RAdam = optim.RAdam(model.parameters(),\n","                  lr = 1e-5,\n","                  betas=(0.9, 0.999),\n","                  weight_decay=0,\n","                  eps = 1e-8,\n","                )\n","# 에폭수\n","epochs = 50\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler_RAdam = get_linear_schedule_with_warmup(optimizer_RAdam,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","\n","model_train(optimizer_RAdam, scheduler_RAdam,  train_dataloader, validation_dataloader)\n","get_eval_accuracy('optimizer_RAdam', test_dataloader, batch_size)"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":16250,"status":"ok","timestamp":1688305096619,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"M6Xs_XldQn9a"},"outputs":[],"source":["# first party와 second party 정보가 담김 party_info_facts 컬럼 추가\n","\n","bert_sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train.facts]\n","\n","labels = train['first_party_winner'].values\n","# tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(s) for s in bert_sentences]\n","\n","MAX_LEN = 512\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# attention_masks\n","attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","# 데이터셋 분리\n","train_X, val_X, train_y, val_y = train_test_split(input_ids,labels,random_state=42,test_size=0.1)\n","\n","train_masks, val_masks, _, _ = train_test_split(attention_masks,\n","                                                       input_ids,\n","                                                       random_state=42,\n","                                                       test_size=0.1)\n","\n","# 파이토치 텐서로 변환\n","train_inputs = torch.tensor(train_X)\n","train_labels = torch.tensor(train_y)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(val_X)\n","validation_labels = torch.tensor(val_y)\n","validation_masks = torch.tensor(val_masks)\n","\n","batch_size = 16\n","train_dataloader, validation_dataloader =  get_train_validation_dataloader(batch_size, train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels )\n","\n","\n","# [CLS] + 문장 + [SEP]\n","bert_sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in test.facts]\n","\n","# 라벨 데이터\n","labels = test['first_party_winner'].values\n","\n","# Word 토크나이저 토큰화\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in bert_sentences]\n","\n","#token의 max length 찾기\n","len_list = [ len(token) for idx, token in enumerate(tokenized_texts)]\n","max_idx = np.where(np.array(len_list) == max(len_list))[0][0]\n","\n","# 시퀀스 설정 및 패딩\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# 어텐션 마스크\n","attention_masks = []\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","# 파이토치 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","test_dataloader = get_test_dataloader(batch_size, test_inputs, test_masks, test_labels)\n","\n"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279981,"status":"ok","timestamp":1688305421508,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"},"user_tz":-540},"id":"HwmPHalYQq7H","outputId":"f6e7d6e1-7f07-4f78-eb81-61b2647baf4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","\n","  Average training loss: 0.58\n","  Training epcoh took: 0:00:51\n","\n","Validation...\n","  Accuracy: 0.61\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","\n","  Average training loss: 0.57\n","  Training epcoh took: 0:00:51\n","\n","Validation...\n","  Accuracy: 0.61\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","\n","  Average training loss: 0.56\n","  Training epcoh took: 0:00:51\n","\n","Validation...\n","  Accuracy: 0.60\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","\n","  Average training loss: 0.52\n","  Training epcoh took: 0:00:51\n","\n","Validation...\n","  Accuracy: 0.59\n","  Validation took: 0:00:02\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","\n","  Average training loss: 0.50\n","  Training epcoh took: 0:00:51\n","\n","Validation...\n","  Accuracy: 0.59\n","  Validation took: 0:00:02\n","\n","======== COMPLETE ========\n","  Batch   100  of    155.    Elapsed: 0:00:11.\n","\n","Accuracy: 0.79\n","Test took: 0:00:18\n"]}],"source":["optimizer_RAdam = optim.RAdam(model.parameters(),\n","                  lr = 1e-5,\n","                  betas=(0.9, 0.999),\n","                  weight_decay=0,\n","                  eps = 1e-8,\n","                )\n","# 에폭수\n","epochs = 5\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler_RAdam = get_linear_schedule_with_warmup(optimizer_RAdam,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","\n","model_train(optimizer_RAdam, scheduler_RAdam,  train_dataloader, validation_dataloader)\n","get_eval_accuracy('optimizer_RAdam', test_dataloader, batch_size)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"uTwOOsMhdtq8","executionInfo":{"status":"ok","timestamp":1688308549894,"user_tz":-540,"elapsed":306,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}}},"outputs":[],"source":["# 문장 테스트\n","def set_eval(test_input, test_masks):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = test_input.to(device)\n","    b_input_mask = test_masks.to(device)\n","\n","    # 그래디언트 계산 안함\n","    with torch.no_grad():\n","        # Forward 수행\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"]},{"cell_type":"code","source":[],"metadata":{"id":"0HIK0DSpCASs"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}